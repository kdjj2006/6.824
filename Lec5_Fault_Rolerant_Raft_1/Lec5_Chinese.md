6.824 2018 第5课: Raft (1)

* 我们为什么要读这篇论文？
    * 分布式共识是人们几十年来一直在努力解决的难题
    * 实验2和实验3基于 Raft
* 本课
    * 今天：Raft 选举和日志处理(实验2A,2B)
    * 下次：Raft 持久化，客户端行为，快照(实验2C,实验3)
* 整体主题：使用复制状态机RSM)的容错服务
    * 例子：配置服务器，像 MapReduce 或者 GFS 的 master
    * 例子：key/value 的存储服务器，put()/get() (实验3)
    * 目标：与单个非复制服务器相同的客户端可见行为，但仍然可用尽管有一些故障服务器
    * 策略：
        * 每个复制服务器按相同顺序执行相同命令
        * 所以他们在执行时仍然是副本(相同)
        * 所以如果一个故障了，其他的可以继续
            * 例如，一个故障，客户端切换到另一个服务器
    * GFS 和 VMware FT 都是这种套路
* 一个重要的问题：如何防止脑裂？
    * 假设客户端可以连接副本A，但连不上副本B
    * 客户端能不能仅仅依靠副本A执行？
    * 如果 B 是真正的崩溃了，客户端必须在没有 B 的情况下执行
        * 否则服务无法容错
    * 如果 B 是启动的，但是网络阻止客户端连接
        * 可能客户端应该在没有它的情况下执行
        * 既然它可能是活着的并且服务其他客户端 -- 脑裂的风险
* 为什么不允许脑裂的例子
    * 容错的 key/value 数据库
    * C1 和 C2 在不同的网络分区并且和不同的服务器交互
         >  C1: put("k1", "v1")  
            C2: put("k1", "v2")   
            C1: get("k1") -> ???  
    * 正确的答案是"v2",因为那是非复制服务器会产生的
    * 但是两个服务器由于分区导致独立的服务器 C1 和 C2
        * C1 的 get 会产生 "v1"
* 难题：计算机无法区分是崩溃的机器还是网络分区，它们的表现都是无法与一台或多台机器通信
* 我们希望有一个能满足下面三个目标的状态机复制方案：
    * 1.保持可用即使任何一个(故障停止)故障
    * 2.处理没有脑裂的分区
    * 3.如果太多故障：等待修复，然后恢复
* 应对分区的重要见解：多数选票
    * 2f+1 台服务器来容忍 f 台故障，例如3台服务器能容忍1台故障
    * 必须取得大数服务器(f+1)的同意才能进行
        * f 台服务器的故障还有大多数(f+1)机器，可以继续工作
    * 为什么大多数可以帮助避免脑裂？
        * 最多一个分区可以占多数    
    * 注意：大多数是指所有 2f+1 服务器中的大多数，不仅仅是活着的服务器中的大多数
    * 关于大多数的真正有用的事情是任何两个必须有交集
        * 交叉路口的服务器只会以某种方式投票
        * 并且交叉点可以传达有关先前决策的信息
* 1990年左右发明了两种分区容忍复制方案
    * Paxos 和 View-Stamped 复制
    * 在最近10年这种技术已在很多现实中应用
    * Raft 论文是对现代技术的很好的介绍
### Raft 论文
#### 主题：Raft 概括
* 使用 Raft 的状态机复制 -- 实验3作为例子
    * 服务器的 Raft 层选出一个领导者
    * 客户端向领导的 k/v 层发送 RPCs
        *  Put, Get, Append
    * k/v 层发送请求给 Raft 层，但不立刻回复客户端
        * 通过 AppendEntries 的 RPC
        * 每个追随者加入自己的本地日志(但还没有提交)
        * 回复领导者已确认
    * 日志条目在领导者中变为"已提交"如果大多数成功放入了它们的日志中
        * 保证不会被遗忘
        * 大多数 -> 下一位领导人的投票请求肯定会被看到
    * 一旦领导者说已经提交，服务器执行对 k/v 执行操作
        * 服务器通过下一个 AppendEntries RPC 发现(通过 commitIndex 字段)
    * 领导者在提交后回复 k/v 层
        * k/v 层执行数据库 Put, 或者取出 Get 结果
    * 然后领导者将执行结果回复给客户端
* 为什么需要日志？
    * 服务保存状态机的状态，例如 key/value 数据库
        * 为什么这个还不够
    * 对命令编号很重要
        * 帮助副本就一个单独的执行达成一致
        * 帮助领导者确保追随者有相同的日志
    * 副本也使用日志来存储命令
        * 直到领导者提交它们
        * 所以领导者可以重发如果一个追随者丢失了一些
        * 为持久化和重启之后的重放(下次)
* 在 Raft 的设计中有两个重要部分
    * 选一个新领导者
    * 确保相同的日志，尽管故障
#### 主题：领导选举(实验 2A)
* 为什么需要一个领导者？
    * 确保所有副本安装相同顺序执行相同命令
* Raft 使用"任期"来对领导的序列号进行编号
    * 新的领导者意味着新的任期
    * 一个任期最多只能有一个领导者；可能没有领导者
    * 一次选举也和一个特别的任期相关联
        * 每个任期只能有一个成功的选举
    * 任期编号帮助服务器追随最新的领导者，不是取代领导者
* Raft 什么时候开始一个领导者选举？
    * AppendEntries是隐含的心跳；领导者定期发送
    * 如果其他的服务器由于“选举超时”没有从当前领导者收到心跳消息
        * 它们认为领导者已经宕机并开始一个新的选举
    * [状态转移图，图4：追随者，候选人，领导者]
    * 追随者增加本地任期号(currentTerm)，编程候选人，开始选举
    * 注意：这可能导致不必要的选举；这个很慢但是安全
    * 注意：旧领导者可能还活着并认为自己是领导者
* 当一个服务器变为候选人会发生什么？
    * 三种可能：
        * 第一种可能
            * 获得大多数选票，变成领导者  
            * 本地观察并统计选票
            * 注意：不能抵抗拜占庭的错误
        * 第二种可能
            * 没有获得大多数选票，从另一个领导者接收消息
            * 通过到来的 AppendEntries RPC
            * 遵循领导者的权威，变为追随者
        * 第三种可能
            * 没有获得大多数选票，但没有收到新领导者的消息
            * 例如，在少数的网络分区
            * 超时并启动另一次选举(还是候选人)
    * 注意，在第三种中，可以继续增加任期号，但是不增加日志条目，既然在少数分区而不是领导者分区，由于更高的任期，选举随之而来    
    但是，要么日志在大多数分区更长(更大任期的候选人被拒绝)；要么一样长，如果在大多数分区什么也没有发生(所以更高任期的候选者赢得选举，但无害)
* 如何确保在一个任期内至多一个领导者？
    * (图2 服务器的 equestVote RPC 和规则)
    * 领导者必须从大多数服务器那里得到赞成选票
    * 一个服务器只能在一个任期内只投一次票
    * 在给定的任期内最多一个服务器可以获得大多数选票
        * 最多一个领导者即使网络分区
        * 选举可以成功即使如果一些服务器发生故障 
* 一个新的领导者如何实现自己？
    * 获胜者从大多数服务器获得赞成选票
    * 立刻给所有人发送 AppendEntries RPC(心跳)
        * 新领导者的心跳取缔任何新的选举
* 由于两个原因一次选举可能不会成功：
    * 不到大多数服务器可以访问
    * 候选人瓜分选票，没人得到大多数选票
* 如果一次选举失败了会发生什么？
    * 另一个超时(没有心跳)，另一次选举
    * 高任期号的优先，为旧任期的选举退出
* 如何设置选举超时？
    * 每个服务器选取一个随机的选举超时时间
        * 帮助避免选票被瓜分
    * 随机性破坏了服务器之间的对称性
        * 一个服务器会选择最小的随机延迟
        * 避免所有人同一时间发起选举，给自己投票
    * 希望有足够的时间在下一次超时到期之前完成选举
    * 其他服务器会看到新领导者的 AppendEntries 心跳并且不会变成候选者
    * 有什么价值？
        * 至少有一些心跳间隔(网络可以删除或者推迟一次心跳)
        * 随机部分足够长来让一个候选者在开始下次选举前成功选举
        * 足够短，以便在测试人员感到不安之前进行一些重试
            * 测试者要求选举在5秒或更短时间内完成
#### 主题：Raft 日志(实验 2B)
* 我们讨论了领导者如何复制日志条目
    * 重要区别：复制的 VS 提交的条目
        * 提交的条目是保证永远不会消失
        * 复制的，但未提交的条目可能被覆盖
    * 有助于想到每个参与者的明确“提交边界”
* 服务器的日志是不是完全相互复制？
    * 不：一些副本可能落后
    * 不：我们会看到它们会临时有不同的条目
    * 好消息：
        * 它们会最终汇合
        * 提交机制确保服务器只会执行可靠的条目
* 其他标准：领导者不能简单的复制提交旧任期的条目
    * [图8 例子]
    * S1 未能将任期2的条目复制到大多数，然后故障了
    * S5 在任期3中变成领导者，增加条目，但是复制失败了
    * S1 回来了，又变成了领导者
        * 从任期2复制旧条目以强制追随者采用其日志
        * 一旦任期2条目在大多数服务器上，我们是否允许提交？
    * 结果答案是不可以。假设如果我们这样做会发生什么：
        * 任期2条目复制到了 S3
        * S1 提交它，既然它在大多数服务器上
        * S1 又故障了
        * S5 在任期4被选举了，它在日志的末尾有任期3的条目
        * 在日志末尾有任期2条目的投票给 S5
    * S5 变成了领导者，现在强制自己的日志(拥有任期3条目)在其他机器上
        * 在索引2处的任期2条目会被任期3条目覆盖
        * 但它被认为是提交了的
        * 因此，与 Leader Completeness 属性相矛盾
    * 解决方法：等到 S1 已经复制并提交了一条任期4条目
        * 确保 S5 在 S1 故障后不会当选
        * 因此提交任期2的条目也没问题
* Raft 什么时候覆盖日志条目是合法的？(图7的问题)
    * 必须是未提交的
    * 可能会截断和覆盖一个更长的日志
        * 图7（f）就是一个例子
    * 例如一个领导者在日志中增加了许多条目，但是未能成功复制它们，可能在一个分区的网络中
    * 其他的领导者在后续的任期中在相同的索引处增加条目(图7 (a)-(e))
        * 并至少提交它们中的一些
        * 现在不能再修改日志索引
    * 过期的服务器收到 AppendEntries，覆盖未提交的日志条目，即使日志比当前领导者的要长
    * 这样没问题，因为领导者只有在条目提交之后才回复
        * 所以在(f)中产生覆盖条目的领导者不可能这样做
#### 附录：实验2 Raft 接口
* rf.Start(command) (index, term, isleader)
    * 实验3 k/v 服务器的 Put()/Get() RPC handlers 调用 Start()
    * 在一个新的日志条目上达成 Raft 协议
    * Start() 立刻返回 -- RPC handler 必须等待提交
    * 如果服务器在提交命令前失去领导权可能不会成功
    * isleader:如果服务器不是 Raft 领导者值是false,客户端应该尝试另外的服务器
    * term:currentTerm，帮助调用者检测领导者是否降级
    * index:记录日志条目以查看命令是否已提交
* ApplyMsg，使用 Index 和 Command
    * Raft 在每个"apply channel"上发送一条消息
    * 提交的日志条目，服务然后知道执行命令，领导者使用 ApplyMsg 去了解 什么时候/什么 去回复给一个在等待的客户端 RPC